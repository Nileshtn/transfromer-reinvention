{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## token based on ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input         : hi there!\n",
      "token         : [104, 105, 32, 116, 104, 101, 114, 101, 33]\n",
      "decoded_token : hi there!\n"
     ]
    }
   ],
   "source": [
    "encoder = lambda input: [ord(char) for char in input]\n",
    "decoder = lambda input: ''.join([chr(char) for char in input])\n",
    "sample_input = \"hi there!\"\n",
    "token = encoder(sample_input)\n",
    "print(f\"input         : {sample_input}\\n\"\n",
    "      f\"token         : {token}\\n\"\n",
    "      f\"decoded_token : {decoder(token)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading the input and tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data length : 1003853\n",
      "val data length : 111540\n"
     ]
    }
   ],
   "source": [
    "with open(\"data.txt\", \"r\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "#converting the word into token and creating a tensor of it\n",
    "token_data = torch.tensor(encoder(data))\n",
    "\n",
    "#spliting data into train and val\n",
    "train_len = int(0.9 * len(token_data))\n",
    "train_data = token_data[:train_len]\n",
    "val_data = token_data[train_len:]\n",
    "\n",
    "print(f\"train data length : {train_data.numel()}\")\n",
    "print(f\"val data length : {val_data.numel()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create the input and traget, with the batch dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "def get_batch(batch, block_len, data):\n",
    "    random_pos = torch.randint(0, len(data)-block_len, (batch,))\n",
    "    input = torch.stack([data[i:i+block_len] for i in random_pos])\n",
    "    target = torch.stack([data[i+1:i+block_len+1] for i in random_pos])\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n",
      "input : \n",
      "[[108 100  32 109  97 114 114 105]\n",
      " [101  32 109 101 110  32  99  97]\n",
      " [ 65 110  32 121 101 116  44  32]\n",
      " [116  39 115 121  32 119 111 114]]\n",
      "output: \n",
      "[[100  32 109  97 114 114 105  97]\n",
      " [ 32 109 101 110  32  99  97 110]\n",
      " [110  32 121 101 116  44  32 102]\n",
      " [ 39 115 121  32 119 111 114 116]]\n"
     ]
    }
   ],
   "source": [
    "batch = 4\n",
    "block_len = 8\n",
    "ipt, tgt = get_batch(batch, block_len, train_data)\n",
    "print(ipt.shape)\n",
    "print(f\"input : \\n{ipt.numpy()}\\n\"\n",
    "      f\"output: \\n{tgt.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, embedding_dim=64, n_vocal=128, context_len=50):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(n_vocal, embedding_dim) # (vocab_size, embedding_dim)\n",
    "        self.time_embedding = nn.Parameter(torch.randn((embedding_dim, context_len))) # (embedding_dim, context_len)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, context_len = x.shape\n",
    "        time_range = torch.arange(context_len, device=x.device)\n",
    "        time_embed = self.time_embedding[:, time_range].unsqueeze(0).expand(batch, -1, -1)\n",
    "        token_embed = self.token_embedding(x)\n",
    "        teken_embed = self.dropout(token_embed)\n",
    "        return time_embed.permute(0, 2, 1) + token_embed  # (batch, context_len, embedding_dim)\n",
    "\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, context_len=50, embedding_dim=64, attention_dim=8, mode=\"encoder\"):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(embedding_dim, attention_dim, bias=False)\n",
    "        self.value = nn.Linear(embedding_dim, attention_dim, bias=False)\n",
    "        self.key = nn.Linear(embedding_dim, attention_dim, bias=False)\n",
    "        self.mode = mode\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_len, context_len)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, c = x.shape  \n",
    "        q = self.query(x)  \n",
    "        k = self.key(x)    \n",
    "        v = self.value(x)  \n",
    "        d_k = q.shape[-1]\n",
    "        scaled_scores = torch.bmm(q, k.permute(0, 2, 1)) / (d_k ** 0.5)\n",
    "\n",
    "        if self.mode == \"encoder\":\n",
    "            attn_weights = scaled_scores\n",
    "        else:\n",
    "            attn_weights = scaled_scores.masked_fill(self.tril[:t, :t] == 0, float('-inf'))\n",
    "        \n",
    "        attn_weights = F.softmax(attn_weights, dim=-1)  \n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        attention_output = torch.bmm(attn_weights, v)  \n",
    "        return attention_output  \n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, context_l=50, embedding_dim=64, heads=8, mode=\"decoder\"):\n",
    "        super().__init__()\n",
    "        self.attention_dim = embedding_dim // heads\n",
    "        self.heads = nn.ModuleList([\n",
    "            Head(context_len=context_l, embedding_dim=embedding_dim, attention_dim=self.attention_dim, mode=mode)\n",
    "            for _ in range(heads)\n",
    "        ])\n",
    "        self.projection_weight = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, c = x.shape\n",
    "        x_ln = F.layer_norm(x, (c,))  # Correct normalization\n",
    "        output = [head(x_ln) for head in self.heads]\n",
    "        output = torch.cat(output, dim=2)\n",
    "        x_p = self.projection_weight(output)\n",
    "        x_p = self.dropout(x_p)\n",
    "        return x + x_p\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, embedding_dim=64, mlp_multiplier=4):\n",
    "        super().__init__()\n",
    "        self.mlp_weight = nn.Linear(embedding_dim, embedding_dim * mlp_multiplier)\n",
    "        self.mlp_projection = nn.Linear(embedding_dim * mlp_multiplier, embedding_dim)\n",
    "        self.gelu1 = nn.GELU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, c = x.shape\n",
    "        x_ln = F.layer_norm(x, (c,))\n",
    "        output = self.gelu1(self.mlp_weight(x_ln))\n",
    "        output = self.dropout(output)\n",
    "        output = self.mlp_projection(output)\n",
    "        return x + output\n",
    "\n",
    "class Logits(nn.Module):\n",
    "    def __init__(self, n_vocal=128, embedding_dim=64):\n",
    "        super().__init__()\n",
    "        self.encode = nn.Linear(embedding_dim, n_vocal, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, c = x.shape\n",
    "        x_ln = F.layer_norm(x, (c,))  # Normalize across channels (embedding dim)\n",
    "        logits = self.encode(x_ln)  # (b, t, n_vocal)\n",
    "        return logits  # No softmax applied\n",
    "\n",
    "class TransformerMini(nn.Module):\n",
    "    def __init__(self, context_l=50, n_vocal=128, embedding_dim=64, attention_heads=8, mode=\"decoder\"):\n",
    "        super().__init__()\n",
    "        self.embedding = Embedding(embedding_dim, n_vocal, context_l)\n",
    "        self.self_attention = SelfAttention(context_l, embedding_dim, attention_heads, mode)\n",
    "        self.mlp = MLP(embedding_dim)\n",
    "        self.logits = Logits(n_vocal, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.self_attention(x)\n",
    "        x = self.mlp(x)\n",
    "        x = self.logits(x)\n",
    "        return x  # Output shape: (batch, context_len, n_vocal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lr = 1e-3\n",
    "batch = 64\n",
    "epoch = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128//16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerMini(\n",
       "  (embedding): Embedding(\n",
       "    (token_embedding): Embedding(128, 128)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (self_attention): SelfAttention(\n",
       "    (heads): ModuleList(\n",
       "      (0-15): 16 x Head(\n",
       "        (query): Linear(in_features=128, out_features=8, bias=False)\n",
       "        (value): Linear(in_features=128, out_features=8, bias=False)\n",
       "        (key): Linear(in_features=128, out_features=8, bias=False)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (projection_weight): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (mlp_weight): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (mlp_projection): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (gelu1): GELU(approximate='none')\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (logits): Logits(\n",
       "    (encode): Linear(in_features=128, out_features=128, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransformerMini(context_l=256, embedding_dim=128, attention_heads=16).to(device=device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr)\n",
    "crtirion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128])\n",
      "epoch : 0, train_l : 5.019121170043945, val_l : 5.017431735992432\n",
      "torch.Size([64, 128])\n",
      "epoch : 1, train_l : 4.999518394470215, val_l : 5.0017194747924805\n",
      "torch.Size([64, 128])\n",
      "epoch : 2, train_l : 4.988387584686279, val_l : 5.003236293792725\n",
      "torch.Size([64, 128])\n",
      "epoch : 3, train_l : 4.965498447418213, val_l : 4.990217208862305\n",
      "torch.Size([64, 128])\n",
      "epoch : 4, train_l : 4.960470199584961, val_l : 4.970786094665527\n",
      "torch.Size([64, 128])\n",
      "epoch : 5, train_l : 4.947319030761719, val_l : 4.966724872589111\n",
      "torch.Size([64, 128])\n",
      "epoch : 6, train_l : 4.930920124053955, val_l : 4.9585371017456055\n",
      "torch.Size([64, 128])\n",
      "epoch : 7, train_l : 4.932190895080566, val_l : 4.956240177154541\n",
      "torch.Size([64, 128])\n",
      "epoch : 8, train_l : 4.910511493682861, val_l : 4.944454669952393\n",
      "torch.Size([64, 128])\n",
      "epoch : 9, train_l : 4.89579963684082, val_l : 4.941092491149902\n",
      "torch.Size([64, 128])\n",
      "epoch : 10, train_l : 4.893231391906738, val_l : 4.935298919677734\n",
      "torch.Size([64, 128])\n",
      "epoch : 11, train_l : 4.864498615264893, val_l : 4.909059524536133\n",
      "torch.Size([64, 128])\n",
      "epoch : 12, train_l : 4.8651204109191895, val_l : 4.925894260406494\n",
      "torch.Size([64, 128])\n",
      "epoch : 13, train_l : 4.8510565757751465, val_l : 4.895702838897705\n",
      "torch.Size([64, 128])\n",
      "epoch : 14, train_l : 4.83984375, val_l : 4.890470504760742\n",
      "torch.Size([64, 128])\n",
      "epoch : 15, train_l : 4.8295207023620605, val_l : 4.884435176849365\n",
      "torch.Size([64, 128])\n",
      "epoch : 16, train_l : 4.817999839782715, val_l : 4.8780317306518555\n",
      "torch.Size([64, 128])\n",
      "epoch : 17, train_l : 4.790024280548096, val_l : 4.862905502319336\n",
      "torch.Size([64, 128])\n",
      "epoch : 18, train_l : 4.789855003356934, val_l : 4.842949867248535\n",
      "torch.Size([64, 128])\n",
      "epoch : 19, train_l : 4.786409378051758, val_l : 4.848672866821289\n",
      "torch.Size([64, 128])\n",
      "epoch : 20, train_l : 4.76593542098999, val_l : 4.839189052581787\n",
      "torch.Size([64, 128])\n",
      "epoch : 21, train_l : 4.745037078857422, val_l : 4.830872535705566\n",
      "torch.Size([64, 128])\n",
      "epoch : 22, train_l : 4.7402472496032715, val_l : 4.8155741691589355\n",
      "torch.Size([64, 128])\n",
      "epoch : 23, train_l : 4.726284503936768, val_l : 4.808488845825195\n",
      "torch.Size([64, 128])\n",
      "epoch : 24, train_l : 4.704359531402588, val_l : 4.792139530181885\n",
      "torch.Size([64, 128])\n",
      "epoch : 25, train_l : 4.696603298187256, val_l : 4.776727199554443\n",
      "torch.Size([64, 128])\n",
      "epoch : 26, train_l : 4.693424701690674, val_l : 4.773836135864258\n",
      "torch.Size([64, 128])\n",
      "epoch : 27, train_l : 4.671769142150879, val_l : 4.7598114013671875\n",
      "torch.Size([64, 128])\n",
      "epoch : 28, train_l : 4.6584601402282715, val_l : 4.7580180168151855\n",
      "torch.Size([64, 128])\n",
      "epoch : 29, train_l : 4.657486915588379, val_l : 4.74668550491333\n",
      "torch.Size([64, 128])\n",
      "epoch : 30, train_l : 4.630585670471191, val_l : 4.727370262145996\n",
      "torch.Size([64, 128])\n",
      "epoch : 31, train_l : 4.592161655426025, val_l : 4.708258628845215\n",
      "torch.Size([64, 128])\n",
      "epoch : 32, train_l : 4.606907367706299, val_l : 4.708322525024414\n",
      "torch.Size([64, 128])\n",
      "epoch : 33, train_l : 4.591459274291992, val_l : 4.698714733123779\n",
      "torch.Size([64, 128])\n",
      "epoch : 34, train_l : 4.576540470123291, val_l : 4.702660083770752\n",
      "torch.Size([64, 128])\n",
      "epoch : 35, train_l : 4.5671892166137695, val_l : 4.678571701049805\n",
      "torch.Size([64, 128])\n",
      "epoch : 36, train_l : 4.546792030334473, val_l : 4.669780731201172\n",
      "torch.Size([64, 128])\n",
      "epoch : 37, train_l : 4.527745246887207, val_l : 4.643370151519775\n",
      "torch.Size([64, 128])\n",
      "epoch : 38, train_l : 4.5169172286987305, val_l : 4.637080192565918\n",
      "torch.Size([64, 128])\n",
      "epoch : 39, train_l : 4.497413158416748, val_l : 4.625424861907959\n",
      "torch.Size([64, 128])\n",
      "epoch : 40, train_l : 4.49703311920166, val_l : 4.621959209442139\n",
      "torch.Size([64, 128])\n",
      "epoch : 41, train_l : 4.470714092254639, val_l : 4.596860885620117\n",
      "torch.Size([64, 128])\n",
      "epoch : 42, train_l : 4.470165729522705, val_l : 4.591348648071289\n",
      "torch.Size([64, 128])\n",
      "epoch : 43, train_l : 4.43711519241333, val_l : 4.56377649307251\n",
      "torch.Size([64, 128])\n",
      "epoch : 44, train_l : 4.410759925842285, val_l : 4.5508012771606445\n",
      "torch.Size([64, 128])\n",
      "epoch : 45, train_l : 4.393966197967529, val_l : 4.542055606842041\n",
      "torch.Size([64, 128])\n",
      "epoch : 46, train_l : 4.3889923095703125, val_l : 4.531103134155273\n",
      "torch.Size([64, 128])\n",
      "epoch : 47, train_l : 4.373537540435791, val_l : 4.511831283569336\n",
      "torch.Size([64, 128])\n",
      "epoch : 48, train_l : 4.351947784423828, val_l : 4.493154048919678\n",
      "torch.Size([64, 128])\n",
      "epoch : 49, train_l : 4.31146764755249, val_l : 4.470510005950928\n",
      "torch.Size([64, 128])\n",
      "epoch : 50, train_l : 4.306952476501465, val_l : 4.4586663246154785\n",
      "torch.Size([64, 128])\n",
      "epoch : 51, train_l : 4.294826507568359, val_l : 4.452304363250732\n",
      "torch.Size([64, 128])\n",
      "epoch : 52, train_l : 4.280655860900879, val_l : 4.439126014709473\n",
      "torch.Size([64, 128])\n",
      "epoch : 53, train_l : 4.2654266357421875, val_l : 4.40995979309082\n",
      "torch.Size([64, 128])\n",
      "epoch : 54, train_l : 4.2214884757995605, val_l : 4.383284568786621\n",
      "torch.Size([64, 128])\n",
      "epoch : 55, train_l : 4.2327351570129395, val_l : 4.38973331451416\n",
      "torch.Size([64, 128])\n",
      "epoch : 56, train_l : 4.205576419830322, val_l : 4.368266582489014\n",
      "torch.Size([64, 128])\n",
      "epoch : 57, train_l : 4.1696062088012695, val_l : 4.342071533203125\n",
      "torch.Size([64, 128])\n",
      "epoch : 58, train_l : 4.154962539672852, val_l : 4.330851078033447\n",
      "torch.Size([64, 128])\n",
      "epoch : 59, train_l : 4.159984111785889, val_l : 4.321804523468018\n",
      "torch.Size([64, 128])\n",
      "epoch : 60, train_l : 4.134490966796875, val_l : 4.295642375946045\n",
      "torch.Size([64, 128])\n",
      "epoch : 61, train_l : 4.124512672424316, val_l : 4.282289505004883\n",
      "torch.Size([64, 128])\n",
      "epoch : 62, train_l : 4.092192649841309, val_l : 4.261119365692139\n",
      "torch.Size([64, 128])\n",
      "epoch : 63, train_l : 4.084166049957275, val_l : 4.25517463684082\n",
      "torch.Size([64, 128])\n",
      "epoch : 64, train_l : 4.0561981201171875, val_l : 4.226500034332275\n",
      "torch.Size([64, 128])\n",
      "epoch : 65, train_l : 4.028690338134766, val_l : 4.207887649536133\n",
      "torch.Size([64, 128])\n",
      "epoch : 66, train_l : 4.014837265014648, val_l : 4.197661876678467\n",
      "torch.Size([64, 128])\n",
      "epoch : 67, train_l : 3.995670795440674, val_l : 4.166833400726318\n",
      "torch.Size([64, 128])\n",
      "epoch : 68, train_l : 3.9792585372924805, val_l : 4.154141426086426\n",
      "torch.Size([64, 128])\n",
      "epoch : 69, train_l : 3.9443066120147705, val_l : 4.123072624206543\n",
      "torch.Size([64, 128])\n",
      "epoch : 70, train_l : 3.9288175106048584, val_l : 4.115480899810791\n",
      "torch.Size([64, 128])\n",
      "epoch : 71, train_l : 3.943176031112671, val_l : 4.112177848815918\n",
      "torch.Size([64, 128])\n",
      "epoch : 72, train_l : 3.8905794620513916, val_l : 4.074383735656738\n",
      "torch.Size([64, 128])\n",
      "epoch : 73, train_l : 3.886221170425415, val_l : 4.069882869720459\n",
      "torch.Size([64, 128])\n",
      "epoch : 74, train_l : 3.838294744491577, val_l : 4.025720596313477\n",
      "torch.Size([64, 128])\n",
      "epoch : 75, train_l : 3.8473613262176514, val_l : 4.030804634094238\n",
      "torch.Size([64, 128])\n",
      "epoch : 76, train_l : 3.795438528060913, val_l : 3.974158763885498\n",
      "torch.Size([64, 128])\n",
      "epoch : 77, train_l : 3.783867120742798, val_l : 3.9782207012176514\n",
      "torch.Size([64, 128])\n",
      "epoch : 78, train_l : 3.797962188720703, val_l : 3.9899353981018066\n",
      "torch.Size([64, 128])\n",
      "epoch : 79, train_l : 3.7800142765045166, val_l : 3.970815896987915\n",
      "torch.Size([64, 128])\n",
      "epoch : 80, train_l : 3.7367935180664062, val_l : 3.9194159507751465\n",
      "torch.Size([64, 128])\n",
      "epoch : 81, train_l : 3.731522560119629, val_l : 3.923865556716919\n",
      "torch.Size([64, 128])\n",
      "epoch : 82, train_l : 3.7106399536132812, val_l : 3.9007930755615234\n",
      "torch.Size([64, 128])\n",
      "epoch : 83, train_l : 3.705754041671753, val_l : 3.915724277496338\n",
      "torch.Size([64, 128])\n",
      "epoch : 84, train_l : 3.68923020362854, val_l : 3.889005661010742\n",
      "torch.Size([64, 128])\n",
      "epoch : 85, train_l : 3.662958860397339, val_l : 3.858151435852051\n",
      "torch.Size([64, 128])\n",
      "epoch : 86, train_l : 3.654554843902588, val_l : 3.8584697246551514\n",
      "torch.Size([64, 128])\n",
      "epoch : 87, train_l : 3.6174116134643555, val_l : 3.8138370513916016\n",
      "torch.Size([64, 128])\n",
      "epoch : 88, train_l : 3.616912603378296, val_l : 3.814209461212158\n",
      "torch.Size([64, 128])\n",
      "epoch : 89, train_l : 3.6366829872131348, val_l : 3.8355116844177246\n",
      "torch.Size([64, 128])\n",
      "epoch : 90, train_l : 3.601644515991211, val_l : 3.80549693107605\n",
      "torch.Size([64, 128])\n",
      "epoch : 91, train_l : 3.55912709236145, val_l : 3.7773053646087646\n",
      "torch.Size([64, 128])\n",
      "epoch : 92, train_l : 3.5674757957458496, val_l : 3.7806901931762695\n",
      "torch.Size([64, 128])\n",
      "epoch : 93, train_l : 3.5369527339935303, val_l : 3.7457356452941895\n",
      "torch.Size([64, 128])\n",
      "epoch : 94, train_l : 3.5504631996154785, val_l : 3.756600856781006\n",
      "torch.Size([64, 128])\n",
      "epoch : 95, train_l : 3.5204672813415527, val_l : 3.724957227706909\n",
      "torch.Size([64, 128])\n",
      "epoch : 96, train_l : 3.5261547565460205, val_l : 3.739241123199463\n",
      "torch.Size([64, 128])\n",
      "epoch : 97, train_l : 3.482072353363037, val_l : 3.685246467590332\n",
      "torch.Size([64, 128])\n",
      "epoch : 98, train_l : 3.5218703746795654, val_l : 3.7331135272979736\n",
      "torch.Size([64, 128])\n",
      "epoch : 99, train_l : 3.4860851764678955, val_l : 3.6891603469848633\n",
      "torch.Size([64, 128])\n",
      "epoch : 100, train_l : 3.5158851146698, val_l : 3.7241878509521484\n",
      "torch.Size([64, 128])\n",
      "epoch : 101, train_l : 3.438913106918335, val_l : 3.6523525714874268\n",
      "torch.Size([64, 128])\n",
      "epoch : 102, train_l : 3.449174165725708, val_l : 3.660248041152954\n",
      "torch.Size([64, 128])\n",
      "epoch : 103, train_l : 3.4647324085235596, val_l : 3.6755943298339844\n",
      "torch.Size([64, 128])\n",
      "epoch : 104, train_l : 3.4108920097351074, val_l : 3.6262946128845215\n",
      "torch.Size([64, 128])\n",
      "epoch : 105, train_l : 3.389707565307617, val_l : 3.59982967376709\n",
      "torch.Size([64, 128])\n",
      "epoch : 106, train_l : 3.4084506034851074, val_l : 3.623577117919922\n",
      "torch.Size([64, 128])\n",
      "epoch : 107, train_l : 3.4431962966918945, val_l : 3.6674816608428955\n",
      "torch.Size([64, 128])\n",
      "epoch : 108, train_l : 3.383204221725464, val_l : 3.6157257556915283\n",
      "torch.Size([64, 128])\n",
      "epoch : 109, train_l : 3.423828363418579, val_l : 3.6422476768493652\n",
      "torch.Size([64, 128])\n",
      "epoch : 110, train_l : 3.3992133140563965, val_l : 3.634716510772705\n",
      "torch.Size([64, 128])\n",
      "epoch : 111, train_l : 3.35892915725708, val_l : 3.5861830711364746\n",
      "torch.Size([64, 128])\n",
      "epoch : 112, train_l : 3.384492874145508, val_l : 3.6095802783966064\n",
      "torch.Size([64, 128])\n",
      "epoch : 113, train_l : 3.3998353481292725, val_l : 3.6258389949798584\n",
      "torch.Size([64, 128])\n",
      "epoch : 114, train_l : 3.388413667678833, val_l : 3.632929563522339\n",
      "torch.Size([64, 128])\n",
      "epoch : 115, train_l : 3.3187448978424072, val_l : 3.546217918395996\n",
      "torch.Size([64, 128])\n",
      "epoch : 116, train_l : 3.3256375789642334, val_l : 3.5589542388916016\n",
      "torch.Size([64, 128])\n",
      "epoch : 117, train_l : 3.367919921875, val_l : 3.6058685779571533\n",
      "torch.Size([64, 128])\n",
      "epoch : 118, train_l : 3.3399317264556885, val_l : 3.5793044567108154\n",
      "torch.Size([64, 128])\n",
      "epoch : 119, train_l : 3.3568103313446045, val_l : 3.5818874835968018\n",
      "torch.Size([64, 128])\n",
      "epoch : 120, train_l : 3.343839168548584, val_l : 3.584609270095825\n",
      "torch.Size([64, 128])\n",
      "epoch : 121, train_l : 3.3187949657440186, val_l : 3.5654661655426025\n",
      "torch.Size([64, 128])\n",
      "epoch : 122, train_l : 3.317129611968994, val_l : 3.5551531314849854\n",
      "torch.Size([64, 128])\n",
      "epoch : 123, train_l : 3.3212382793426514, val_l : 3.5641369819641113\n",
      "torch.Size([64, 128])\n",
      "epoch : 124, train_l : 3.337900161743164, val_l : 3.589083671569824\n",
      "torch.Size([64, 128])\n",
      "epoch : 125, train_l : 3.3188648223876953, val_l : 3.57271671295166\n",
      "torch.Size([64, 128])\n",
      "epoch : 126, train_l : 3.307908296585083, val_l : 3.5626747608184814\n",
      "torch.Size([64, 128])\n",
      "epoch : 127, train_l : 3.295013427734375, val_l : 3.554285764694214\n",
      "torch.Size([64, 128])\n",
      "epoch : 128, train_l : 3.292621374130249, val_l : 3.5488643646240234\n",
      "torch.Size([64, 128])\n",
      "epoch : 129, train_l : 3.3055014610290527, val_l : 3.569396734237671\n",
      "torch.Size([64, 128])\n",
      "epoch : 130, train_l : 3.2937369346618652, val_l : 3.5616133213043213\n",
      "torch.Size([64, 128])\n",
      "epoch : 131, train_l : 3.2723846435546875, val_l : 3.539151668548584\n",
      "torch.Size([64, 128])\n",
      "epoch : 132, train_l : 3.2844784259796143, val_l : 3.553443431854248\n",
      "torch.Size([64, 128])\n",
      "epoch : 133, train_l : 3.240504503250122, val_l : 3.5104379653930664\n",
      "torch.Size([64, 128])\n",
      "epoch : 134, train_l : 3.254754066467285, val_l : 3.5231168270111084\n",
      "torch.Size([64, 128])\n",
      "epoch : 135, train_l : 3.2464523315429688, val_l : 3.519646167755127\n",
      "torch.Size([64, 128])\n",
      "epoch : 136, train_l : 3.261732816696167, val_l : 3.5204896926879883\n",
      "torch.Size([64, 128])\n",
      "epoch : 137, train_l : 3.295138359069824, val_l : 3.5661513805389404\n",
      "torch.Size([64, 128])\n",
      "epoch : 138, train_l : 3.256932497024536, val_l : 3.5400888919830322\n",
      "torch.Size([64, 128])\n",
      "epoch : 139, train_l : 3.253627300262451, val_l : 3.5247995853424072\n",
      "torch.Size([64, 128])\n",
      "epoch : 140, train_l : 3.2260472774505615, val_l : 3.5065360069274902\n",
      "torch.Size([64, 128])\n",
      "epoch : 141, train_l : 3.230409622192383, val_l : 3.518345832824707\n",
      "torch.Size([64, 128])\n",
      "epoch : 142, train_l : 3.2064452171325684, val_l : 3.499594211578369\n",
      "torch.Size([64, 128])\n",
      "epoch : 143, train_l : 3.2581193447113037, val_l : 3.54182767868042\n",
      "torch.Size([64, 128])\n",
      "epoch : 144, train_l : 3.2035889625549316, val_l : 3.489830493927002\n",
      "torch.Size([64, 128])\n",
      "epoch : 145, train_l : 3.218578577041626, val_l : 3.5129592418670654\n",
      "torch.Size([64, 128])\n",
      "epoch : 146, train_l : 3.202864408493042, val_l : 3.5067780017852783\n",
      "torch.Size([64, 128])\n",
      "epoch : 147, train_l : 3.222886562347412, val_l : 3.52765154838562\n",
      "torch.Size([64, 128])\n",
      "epoch : 148, train_l : 3.1951751708984375, val_l : 3.4927289485931396\n",
      "torch.Size([64, 128])\n",
      "epoch : 149, train_l : 3.180596113204956, val_l : 3.4865009784698486\n",
      "torch.Size([64, 128])\n",
      "epoch : 150, train_l : 3.214512586593628, val_l : 3.5126547813415527\n",
      "torch.Size([64, 128])\n",
      "epoch : 151, train_l : 3.200735330581665, val_l : 3.5224266052246094\n",
      "torch.Size([64, 128])\n",
      "epoch : 152, train_l : 3.2025697231292725, val_l : 3.5248286724090576\n",
      "torch.Size([64, 128])\n",
      "epoch : 153, train_l : 3.1986324787139893, val_l : 3.52046275138855\n",
      "torch.Size([64, 128])\n",
      "epoch : 154, train_l : 3.1978635787963867, val_l : 3.5283782482147217\n",
      "torch.Size([64, 128])\n",
      "epoch : 155, train_l : 3.1489152908325195, val_l : 3.4612843990325928\n",
      "torch.Size([64, 128])\n",
      "epoch : 156, train_l : 3.139230251312256, val_l : 3.468204975128174\n",
      "torch.Size([64, 128])\n",
      "epoch : 157, train_l : 3.1880271434783936, val_l : 3.4965219497680664\n",
      "torch.Size([64, 128])\n",
      "epoch : 158, train_l : 3.165647029876709, val_l : 3.5065689086914062\n",
      "torch.Size([64, 128])\n",
      "epoch : 159, train_l : 3.1793391704559326, val_l : 3.5121097564697266\n",
      "torch.Size([64, 128])\n",
      "epoch : 160, train_l : 3.1800177097320557, val_l : 3.515296697616577\n",
      "torch.Size([64, 128])\n",
      "epoch : 161, train_l : 3.179980754852295, val_l : 3.530627727508545\n",
      "torch.Size([64, 128])\n",
      "epoch : 162, train_l : 3.1947519779205322, val_l : 3.545123338699341\n",
      "torch.Size([64, 128])\n",
      "epoch : 163, train_l : 3.11747670173645, val_l : 3.4750356674194336\n",
      "torch.Size([64, 128])\n",
      "epoch : 164, train_l : 3.177507162094116, val_l : 3.526536226272583\n",
      "torch.Size([64, 128])\n",
      "epoch : 165, train_l : 3.174417495727539, val_l : 3.537802219390869\n",
      "torch.Size([64, 128])\n",
      "epoch : 166, train_l : 3.18143630027771, val_l : 3.5409069061279297\n",
      "torch.Size([64, 128])\n",
      "epoch : 167, train_l : 3.161679744720459, val_l : 3.527846097946167\n",
      "torch.Size([64, 128])\n",
      "epoch : 168, train_l : 3.156562328338623, val_l : 3.527909517288208\n",
      "torch.Size([64, 128])\n",
      "epoch : 169, train_l : 3.1951401233673096, val_l : 3.567539691925049\n",
      "torch.Size([64, 128])\n",
      "epoch : 170, train_l : 3.182814598083496, val_l : 3.5693652629852295\n",
      "torch.Size([64, 128])\n",
      "epoch : 171, train_l : 3.154635429382324, val_l : 3.553424835205078\n",
      "torch.Size([64, 128])\n",
      "epoch : 172, train_l : 3.1458258628845215, val_l : 3.5349490642547607\n",
      "torch.Size([64, 128])\n",
      "epoch : 173, train_l : 3.1503777503967285, val_l : 3.5393054485321045\n",
      "torch.Size([64, 128])\n",
      "epoch : 174, train_l : 3.145332098007202, val_l : 3.540684223175049\n",
      "torch.Size([64, 128])\n",
      "epoch : 175, train_l : 3.156935930252075, val_l : 3.558088779449463\n",
      "torch.Size([64, 128])\n",
      "epoch : 176, train_l : 3.1640005111694336, val_l : 3.5583279132843018\n",
      "torch.Size([64, 128])\n",
      "epoch : 177, train_l : 3.140578269958496, val_l : 3.545687198638916\n",
      "torch.Size([64, 128])\n",
      "epoch : 178, train_l : 3.1105096340179443, val_l : 3.527765989303589\n",
      "torch.Size([64, 128])\n",
      "epoch : 179, train_l : 3.103384256362915, val_l : 3.509343147277832\n",
      "torch.Size([64, 128])\n",
      "epoch : 180, train_l : 3.0934243202209473, val_l : 3.5322329998016357\n",
      "torch.Size([64, 128])\n",
      "epoch : 181, train_l : 3.088801383972168, val_l : 3.5223093032836914\n",
      "torch.Size([64, 128])\n",
      "epoch : 182, train_l : 3.1220736503601074, val_l : 3.5498080253601074\n",
      "torch.Size([64, 128])\n",
      "epoch : 183, train_l : 3.10618257522583, val_l : 3.5191493034362793\n",
      "torch.Size([64, 128])\n",
      "epoch : 184, train_l : 3.1020522117614746, val_l : 3.538343906402588\n",
      "torch.Size([64, 128])\n",
      "epoch : 185, train_l : 3.119847297668457, val_l : 3.5661120414733887\n",
      "torch.Size([64, 128])\n",
      "epoch : 186, train_l : 3.1156985759735107, val_l : 3.5609583854675293\n",
      "torch.Size([64, 128])\n",
      "epoch : 187, train_l : 3.093273639678955, val_l : 3.533869981765747\n",
      "torch.Size([64, 128])\n",
      "epoch : 188, train_l : 3.120290994644165, val_l : 3.5677542686462402\n",
      "torch.Size([64, 128])\n",
      "epoch : 189, train_l : 3.083400249481201, val_l : 3.5462491512298584\n",
      "torch.Size([64, 128])\n",
      "epoch : 190, train_l : 3.0508458614349365, val_l : 3.5100252628326416\n",
      "torch.Size([64, 128])\n",
      "epoch : 191, train_l : 3.078322410583496, val_l : 3.541167736053467\n",
      "torch.Size([64, 128])\n",
      "epoch : 192, train_l : 3.0795207023620605, val_l : 3.5564873218536377\n",
      "torch.Size([64, 128])\n",
      "epoch : 193, train_l : 3.1099066734313965, val_l : 3.567035675048828\n",
      "torch.Size([64, 128])\n",
      "epoch : 194, train_l : 3.071446180343628, val_l : 3.529123544692993\n",
      "torch.Size([64, 128])\n",
      "epoch : 195, train_l : 3.076979875564575, val_l : 3.5465590953826904\n",
      "torch.Size([64, 128])\n",
      "epoch : 196, train_l : 3.073758840560913, val_l : 3.5552685260772705\n",
      "torch.Size([64, 128])\n",
      "epoch : 197, train_l : 3.103118419647217, val_l : 3.5764217376708984\n",
      "torch.Size([64, 128])\n",
      "epoch : 198, train_l : 3.0510666370391846, val_l : 3.541581869125366\n",
      "torch.Size([64, 128])\n",
      "epoch : 199, train_l : 3.068085193634033, val_l : 3.566694974899292\n",
      "torch.Size([64, 128])\n",
      "epoch : 200, train_l : 3.0921690464019775, val_l : 3.5781073570251465\n",
      "torch.Size([64, 128])\n",
      "epoch : 201, train_l : 3.079490900039673, val_l : 3.5859713554382324\n",
      "torch.Size([64, 128])\n",
      "epoch : 202, train_l : 3.085272789001465, val_l : 3.575232982635498\n",
      "torch.Size([64, 128])\n",
      "epoch : 203, train_l : 3.077622652053833, val_l : 3.582151174545288\n",
      "torch.Size([64, 128])\n",
      "epoch : 204, train_l : 3.0617480278015137, val_l : 3.5719046592712402\n",
      "torch.Size([64, 128])\n",
      "epoch : 205, train_l : 3.0840277671813965, val_l : 3.5952908992767334\n",
      "torch.Size([64, 128])\n",
      "epoch : 206, train_l : 3.0450525283813477, val_l : 3.568046808242798\n",
      "torch.Size([64, 128])\n",
      "epoch : 207, train_l : 3.0552926063537598, val_l : 3.5869781970977783\n",
      "torch.Size([64, 128])\n",
      "epoch : 208, train_l : 3.0179247856140137, val_l : 3.5459370613098145\n",
      "torch.Size([64, 128])\n",
      "epoch : 209, train_l : 3.0556397438049316, val_l : 3.583252191543579\n",
      "torch.Size([64, 128])\n",
      "epoch : 210, train_l : 3.065269708633423, val_l : 3.5969862937927246\n",
      "torch.Size([64, 128])\n",
      "epoch : 211, train_l : 3.0326168537139893, val_l : 3.5663862228393555\n",
      "torch.Size([64, 128])\n",
      "epoch : 212, train_l : 3.060375690460205, val_l : 3.571403741836548\n",
      "torch.Size([64, 128])\n",
      "epoch : 213, train_l : 3.0411248207092285, val_l : 3.597527503967285\n",
      "torch.Size([64, 128])\n",
      "epoch : 214, train_l : 3.018745183944702, val_l : 3.5811448097229004\n",
      "torch.Size([64, 128])\n",
      "epoch : 215, train_l : 3.0169053077697754, val_l : 3.560432195663452\n",
      "torch.Size([64, 128])\n",
      "epoch : 216, train_l : 3.0208029747009277, val_l : 3.597212553024292\n",
      "torch.Size([64, 128])\n",
      "epoch : 217, train_l : 3.042144536972046, val_l : 3.6038050651550293\n",
      "torch.Size([64, 128])\n",
      "epoch : 218, train_l : 3.039854049682617, val_l : 3.6057260036468506\n",
      "torch.Size([64, 128])\n",
      "epoch : 219, train_l : 3.0332322120666504, val_l : 3.617105007171631\n",
      "torch.Size([64, 128])\n",
      "epoch : 220, train_l : 3.0274083614349365, val_l : 3.5812089443206787\n",
      "torch.Size([64, 128])\n",
      "epoch : 221, train_l : 3.0043203830718994, val_l : 3.5718042850494385\n",
      "torch.Size([64, 128])\n",
      "epoch : 222, train_l : 3.025149345397949, val_l : 3.604963779449463\n",
      "torch.Size([64, 128])\n",
      "epoch : 223, train_l : 3.037102699279785, val_l : 3.6090779304504395\n",
      "torch.Size([64, 128])\n",
      "epoch : 224, train_l : 3.0546345710754395, val_l : 3.636902332305908\n",
      "torch.Size([64, 128])\n",
      "epoch : 225, train_l : 3.005254030227661, val_l : 3.5960469245910645\n",
      "torch.Size([64, 128])\n",
      "epoch : 226, train_l : 3.0253095626831055, val_l : 3.624568223953247\n",
      "torch.Size([64, 128])\n",
      "epoch : 227, train_l : 3.014101982116699, val_l : 3.6085517406463623\n",
      "torch.Size([64, 128])\n",
      "epoch : 228, train_l : 2.990119218826294, val_l : 3.5965917110443115\n",
      "torch.Size([64, 128])\n",
      "epoch : 229, train_l : 3.042418956756592, val_l : 3.643369197845459\n",
      "torch.Size([64, 128])\n",
      "epoch : 230, train_l : 3.0176949501037598, val_l : 3.6180388927459717\n",
      "torch.Size([64, 128])\n",
      "epoch : 231, train_l : 2.986128568649292, val_l : 3.578939914703369\n",
      "torch.Size([64, 128])\n",
      "epoch : 232, train_l : 2.9868593215942383, val_l : 3.5859923362731934\n",
      "torch.Size([64, 128])\n",
      "epoch : 233, train_l : 3.0228230953216553, val_l : 3.655527353286743\n",
      "torch.Size([64, 128])\n",
      "epoch : 234, train_l : 2.996570587158203, val_l : 3.6198949813842773\n",
      "torch.Size([64, 128])\n",
      "epoch : 235, train_l : 2.9733545780181885, val_l : 3.607717514038086\n",
      "torch.Size([64, 128])\n",
      "epoch : 236, train_l : 2.990104913711548, val_l : 3.6282427310943604\n",
      "torch.Size([64, 128])\n",
      "epoch : 237, train_l : 2.9948012828826904, val_l : 3.6170902252197266\n",
      "torch.Size([64, 128])\n",
      "epoch : 238, train_l : 2.985868215560913, val_l : 3.6226086616516113\n",
      "torch.Size([64, 128])\n",
      "epoch : 239, train_l : 3.000636100769043, val_l : 3.655383348464966\n",
      "torch.Size([64, 128])\n",
      "epoch : 240, train_l : 3.012355089187622, val_l : 3.6406774520874023\n",
      "torch.Size([64, 128])\n",
      "epoch : 241, train_l : 2.996633768081665, val_l : 3.6343891620635986\n",
      "torch.Size([64, 128])\n",
      "epoch : 242, train_l : 2.976130723953247, val_l : 3.6221158504486084\n",
      "torch.Size([64, 128])\n",
      "epoch : 243, train_l : 3.003286361694336, val_l : 3.653913736343384\n",
      "torch.Size([64, 128])\n",
      "epoch : 244, train_l : 2.9506077766418457, val_l : 3.6002390384674072\n",
      "torch.Size([64, 128])\n",
      "epoch : 245, train_l : 2.9839465618133545, val_l : 3.6460020542144775\n",
      "torch.Size([64, 128])\n",
      "epoch : 246, train_l : 2.9559667110443115, val_l : 3.6396372318267822\n",
      "torch.Size([64, 128])\n",
      "epoch : 247, train_l : 2.9761483669281006, val_l : 3.6216416358947754\n",
      "torch.Size([64, 128])\n",
      "epoch : 248, train_l : 2.9884192943573, val_l : 3.6731343269348145\n",
      "torch.Size([64, 128])\n",
      "epoch : 249, train_l : 2.945823907852173, val_l : 3.653427839279175\n",
      "torch.Size([64, 128])\n",
      "epoch : 250, train_l : 2.994682788848877, val_l : 3.6723439693450928\n",
      "torch.Size([64, 128])\n",
      "epoch : 251, train_l : 2.9301812648773193, val_l : 3.608227014541626\n",
      "torch.Size([64, 128])\n",
      "epoch : 252, train_l : 2.961064338684082, val_l : 3.6515016555786133\n",
      "torch.Size([64, 128])\n",
      "epoch : 253, train_l : 2.9732980728149414, val_l : 3.6617515087127686\n",
      "torch.Size([64, 128])\n",
      "epoch : 254, train_l : 2.9861979484558105, val_l : 3.68338680267334\n",
      "torch.Size([64, 128])\n",
      "epoch : 255, train_l : 2.987481117248535, val_l : 3.7083816528320312\n",
      "torch.Size([64, 128])\n",
      "epoch : 256, train_l : 2.995750904083252, val_l : 3.703864336013794\n",
      "torch.Size([64, 128])\n",
      "epoch : 257, train_l : 2.954486608505249, val_l : 3.6840333938598633\n",
      "torch.Size([64, 128])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     17\u001b[39m     b, t, n = output.shape \u001b[38;5;66;03m#(b, t, n)\u001b[39;00m\n\u001b[32m     18\u001b[39m     vloss = crtirion(output.view(b*t, n), yb.view(b*t))\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mF\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mepoch : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, train_l : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, val_l : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvloss.item()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    model.train()\n",
    "    xb, yb = get_batch(batch, 128, train_data)\n",
    "    xb, yb = xb.to(device=device), yb.to(device=device)\n",
    "    print(xb.shape)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(xb)\n",
    "    b, t, n = output.shape #(b, t, n)\n",
    "    loss = crtirion(output.view(b*t, n), yb.view(b*t))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        vxb, vyb = get_batch(batch, 128, val_data)\n",
    "        vxb, vyb = vxb.to(device=device), vyb.to(device=device)\n",
    "        model.eval()\n",
    "        output = model(vxb)\n",
    "        b, t, n = output.shape #(b, t, n)\n",
    "        vloss = crtirion(output.view(b*t, n), vyb.view(b*t))\n",
    "\n",
    "\n",
    "    print(F\"epoch : {i}, train_l : {loss.item()}, val_l : {vloss.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(model:TransformerMini, token_len):\n",
    "    token = torch.tensor([[10]]).to(device)\n",
    "    for i in range(token_len):\n",
    "        out = model(token)\n",
    "        sm_out = F.softmax(out[:,-1,:], dim=-1)\n",
    "        predict = torch.multinomial(sm_out, num_samples=1)\n",
    "        token = torch.cat((token, predict), dim=1)[:, -50:]\n",
    "        print(decoder(predict), end='')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hee\n",
      "\n",
      "L aee s dicY ce kare:.endteUo!daney,gid'.\n",
      "A t\n",
      "\u0004oAd aneod \n",
      "erad\n",
      "Io\u001aallcethe oseofo\n",
      "d torly cinet in hUg Ee&ere d  m he%risa\u0012hs p \\. wanrlld id lleneer wo lc r ur en aan n agasor mr\u0019thte, w hay icorXvhoe f\n",
      "d \u0003hensere pAxIfoiloae o \n",
      "qhe t\n",
      ")\n",
      "mad h\u0018theelarytdutenocerp.othfua{n b th h awin\n",
      "(rineounitheaaufrane\u001eon allly,iis mcere mhar tononad illheroar yea\n",
      "AasuK\u0000it as hothe\n",
      "acI lliled Dgsrnrreaf lH"
     ]
    }
   ],
   "source": [
    "generator(model.eval(), 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
