{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## token based on ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input         : hi there!\n",
      "token         : [104, 105, 32, 116, 104, 101, 114, 101, 33]\n",
      "decoded_token : hi there!\n"
     ]
    }
   ],
   "source": [
    "encoder = lambda input: [ord(char) for char in input]\n",
    "decoder = lambda input: ''.join([chr(char) for char in input])\n",
    "sample_input = \"hi there!\"\n",
    "token = encoder(sample_input)\n",
    "print(f\"input         : {sample_input}\\n\"\n",
    "      f\"token         : {token}\\n\"\n",
    "      f\"decoded_token : {decoder(token)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading the input and tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data length : 1003853\n",
      "val data length : 111540\n"
     ]
    }
   ],
   "source": [
    "with open(\"data.txt\", \"r\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "#converting the word into token and creating a tensor of it\n",
    "token_data = torch.tensor(encoder(data))\n",
    "\n",
    "#spliting data into train and val\n",
    "train_len = int(0.9 * len(token_data))\n",
    "train_data = token_data[:train_len]\n",
    "val_data = token_data[train_len:]\n",
    "\n",
    "print(f\"train data length : {train_data.numel()}\")\n",
    "print(f\"val data length : {val_data.numel()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create the input and traget, with the batch dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "def get_batch(batch, block_len, data):\n",
    "    random_pos = torch.randint(0, len(data)-block_len, (batch,))\n",
    "    input = torch.stack([data[i:i+block_len] for i in random_pos])\n",
    "    target = torch.stack([data[i+1:i+block_len+1] for i in random_pos])\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n",
      "input : \n",
      "[[108 100  32 109  97 114 114 105]\n",
      " [101  32 109 101 110  32  99  97]\n",
      " [ 65 110  32 121 101 116  44  32]\n",
      " [116  39 115 121  32 119 111 114]]\n",
      "output: \n",
      "[[100  32 109  97 114 114 105  97]\n",
      " [ 32 109 101 110  32  99  97 110]\n",
      " [110  32 121 101 116  44  32 102]\n",
      " [ 39 115 121  32 119 111 114 116]]\n"
     ]
    }
   ],
   "source": [
    "batch = 4\n",
    "block_len = 8\n",
    "ipt, tgt = get_batch(batch, block_len, train_data)\n",
    "print(ipt.shape)\n",
    "print(f\"input : \\n{ipt.numpy()}\\n\"\n",
    "      f\"output: \\n{tgt.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, embedding_dim=64, vocab_len=128, context_len=50):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_len, embedding_dim) #v,c\n",
    "        self.time_embedding = nn.Parameter(torch.randn((embedding_dim, context_len))) #v,l\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, context_len = x.shape\n",
    "        time_range = torch.arange(context_len, device=x.device)\n",
    "        time_embed = self.time_embedding[:, time_range].unsqueeze(0).expand(batch, -1, -1)\n",
    "        token_embed = self.token_embedding(x)\n",
    "\n",
    "        return time_embed.permute(0,2,1) + token_embed # (b, t, c)\n",
    "    \n",
    "class Head(nn.Module):\n",
    "    def __init__(self, context_len=50, embedding_dim=64, attention_dim=8, mode=\"encoder\"):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(embedding_dim, attention_dim, bias=False)\n",
    "        self.value = nn.Linear(embedding_dim, attention_dim, bias=False)\n",
    "        self.key = nn.Linear(embedding_dim, attention_dim, bias=False)\n",
    "        self.mode = mode\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_len, context_len)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, c = x.shape  # (b, t, c)\n",
    "        # Compute Q, K, V\n",
    "        q = self.query(x)  # (b, t, a)\n",
    "        k = self.key(x)    # (b, t, a)\n",
    "        v = self.value(x)  # (b, t, a)\n",
    "        # Compute scaled dot-product attention\n",
    "        d_k = q.shape[-1]\n",
    "        scaled_scores = torch.bmm(q, k.permute(0, 2, 1)) / (d_k ** 0.5)\n",
    "        if self.mode==\"encoder\":\n",
    "            attn_weights = scaled_scores\n",
    "        else:\n",
    "            attn_weights = scaled_scores.masked_fill(self.tril[:t, :t]==0, float('-inf'))# (b, t, a).(b, a, t) -> (b, t, t)\n",
    "        attn_weights = F.softmax(attn_weights, dim=-1)  # (b, t, a).(b, a, t) -> (b, t, t)\n",
    "        attention_output = torch.bmm(attn_weights, v)  #(b,t,a).(b, t, t) -> (b, t, a)\n",
    "        return attention_output #(b, t, a)\n",
    "    \n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim=64, heads=8, mode=\"decoder\"):\n",
    "        super().__init__()\n",
    "        self.attention_dim = embedding_dim//heads\n",
    "        self.heads = nn.ModuleList([Head(context_len=50, \n",
    "                                         embedding_dim=embedding_dim, \n",
    "                                         attention_dim=self.attention_dim, \n",
    "                                         mode=mode) for _ in range(heads)])\n",
    "        self.projection_weight = nn.Linear(embedding_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, c = x.shape\n",
    "        x_ln = F.layer_norm(x, (t, c))\n",
    "        output = [head(x_ln) for head in self.heads]\n",
    "        output = torch.cat(output, dim=2) #cat on the channel or attention dimention in my case its 2\n",
    "        x_p = self.projection_weight(output)\n",
    "        return x + x_p\n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, embedding_dim=64, mpl_multipler=4):\n",
    "        super().__init__()\n",
    "        self.mlp_weight = nn.Linear(embedding_dim, embedding_dim*mpl_multipler)\n",
    "        self.mpl_projection = nn.Linear(embedding_dim*mpl_multipler, embedding_dim)\n",
    "        self.gelu1 = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, c = x.shape\n",
    "        x_ln = F.layer_norm(x, (t, c))\n",
    "        output = self.gelu1(self.mlp_weight(x_ln))\n",
    "        output = self.mpl_projection(output)\n",
    "        return x + output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "em = Embedding()\n",
    "a = SelfAttention()\n",
    "mlp = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randint(0,10, (4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5, 64])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_in = em(input)\n",
    "print(em_in.shape)\n",
    "a_in = a(em_in)\n",
    "a_in.shape\n",
    "mlp_in = mlp(a_in)\n",
    "mlp_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
